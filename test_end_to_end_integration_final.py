"""
æœ€ç»ˆç‰ˆç«¯åˆ°ç«¯é›†æˆæµ‹è¯• (Final End-to-End Integration Tests)
ä¸“æ³¨äºæ ¸å¿ƒä¸šåŠ¡æµç¨‹æµ‹è¯•ï¼Œç®€åŒ–è®¤è¯å’Œæ•°æ®åº“é…ç½®

Feature: express-tracking-website, Task 12.1: ç¼–å†™ç«¯åˆ°ç«¯é›†æˆæµ‹è¯•
"""

import pytest
import asyncio
import json
import io
import csv
from datetime import datetime, date
from decimal import Decimal
from unittest.mock import Mock, AsyncMock, patch

# ç›´æ¥æµ‹è¯•æœåŠ¡å±‚ï¼Œé¿å…å¤æ‚çš„APIå’Œè®¤è¯é—®é¢˜
from app.services.intelligent_query_service import IntelligentQueryService
from app.services.manifest_service import ManifestService
from app.services.file_processor_service import FileProcessorService
from app.services.data_sync_service import data_sync_service
from app.models.cargo_manifest import CargoManifest


class MockDatabase:
    """æ¨¡æ‹Ÿæ•°æ®åº“ä¼šè¯"""
    
    def __init__(self):
        self.manifests = {}
        self.id_counter = 1
    
    def add(self, manifest):
        """æ·»åŠ ç†è´§å•"""
        manifest.id = self.id_counter
        self.id_counter += 1
        self.manifests[manifest.tracking_number] = manifest
    
    def commit(self):
        """æäº¤äº‹åŠ¡"""
        pass
    
    def rollback(self):
        """å›æ»šäº‹åŠ¡"""
        pass
    
    def refresh(self, obj):
        """åˆ·æ–°å¯¹è±¡"""
        pass
    
    def query(self, model):
        """æŸ¥è¯¢æ¨¡å‹"""
        return MockQuery(self.manifests)
    
    def close(self):
        """å…³é—­ä¼šè¯"""
        pass


class MockQuery:
    """æ¨¡æ‹ŸæŸ¥è¯¢å¯¹è±¡"""
    
    def __init__(self, manifests):
        self.manifests = manifests
        self.filters = []
    
    def filter(self, condition):
        """æ·»åŠ è¿‡æ»¤æ¡ä»¶"""
        # ç®€åŒ–å¤„ç†ï¼Œåªå¤„ç†tracking_numberæŸ¥è¯¢
        return self
    
    def order_by(self, *args):
        """æ’åº"""
        return self
    
    def offset(self, offset):
        """åç§»"""
        return self
    
    def limit(self, limit):
        """é™åˆ¶"""
        return self
    
    def first(self):
        """è·å–ç¬¬ä¸€ä¸ªç»“æœ"""
        # ç®€åŒ–å¤„ç†ï¼Œè¿”å›ä»»æ„ä¸€ä¸ªç†è´§å•ç”¨äºæµ‹è¯•
        if self.manifests:
            return list(self.manifests.values())[0]
        return None
    
    def all(self):
        """è·å–æ‰€æœ‰ç»“æœ"""
        return list(self.manifests.values())
    
    def count(self):
        """è·å–æ•°é‡"""
        return len(self.manifests)


class TestEndToEndIntegrationFinal:
    """æœ€ç»ˆç‰ˆç«¯åˆ°ç«¯é›†æˆæµ‹è¯•ç±»"""
    
    def setup_method(self):
        """æµ‹è¯•å‰å‡†å¤‡"""
        self.mock_db = MockDatabase()
        
        # æ¸…ç†ç¼“å­˜å’ŒåŒæ­¥çŠ¶æ€
        data_sync_service.invalidate_all_cache()
        data_sync_service.clear_pending_sync_operations()
    
    def create_test_csv_content(self, data):
        """åˆ›å»ºæµ‹è¯•CSVå†…å®¹"""
        output = io.StringIO()
        writer = csv.DictWriter(output, fieldnames=[
            'å¿«é€’å•å·', 'ç†è´§æ—¥æœŸ', 'è¿è¾“ä»£ç ', 
            'å®¢æˆ·ä»£ç ', 'è´§ç‰©ä»£ç ', 'é›†åŒ…å•å·', 
            'é‡é‡', 'é•¿åº¦', 'å®½åº¦', 'é«˜åº¦', 'ç‰¹æ®Šè´¹ç”¨'
        ])
        writer.writeheader()
        writer.writerows(data)
        
        csv_content = output.getvalue()
        output.close()
        
        return csv_content.encode('utf-8')
    
    def test_complete_query_flow_with_package_association(self):
        """
        æµ‹è¯•å®Œæ•´çš„æŸ¥è¯¢æµç¨‹ - æœ‰é›†åŒ…å•å·å…³è”
        
        æµ‹è¯•åœºæ™¯ï¼š
        1. ä¸Šä¼ ç†è´§å•æ•°æ®
        2. æŸ¥è¯¢æœ‰é›†åŒ…å•å·çš„å¿«é€’
        3. éªŒè¯æ™ºèƒ½åˆ¤æ–­é€»è¾‘
        4. éªŒè¯APIè°ƒç”¨å‚æ•°
        """
        print("ğŸ” æµ‹è¯•å®Œæ•´çš„æŸ¥è¯¢æµç¨‹ - æœ‰é›†åŒ…å•å·å…³è”")
        
        # Step 1: åˆ›å»ºç†è´§å•æ•°æ®
        print("  ğŸ“¤ Step 1: åˆ›å»ºç†è´§å•æ•°æ®")
        
        manifest = CargoManifest(
            tracking_number='E2ETEST001',
            manifest_date=date(2024, 1, 15),
            transport_code='TC001',
            customer_code='CC001',
            goods_code='GC001',
            package_number='PKGE2E001',
            weight=Decimal('2.5')
        )
        
        self.mock_db.add(manifest)
        self.mock_db.commit()
        
        print("    âœ“ ç†è´§å•æ•°æ®åˆ›å»ºæˆåŠŸ")
        
        # Step 2: æµ‹è¯•æ™ºèƒ½æŸ¥è¯¢æœåŠ¡
        print("  ğŸ” Step 2: æµ‹è¯•æ™ºèƒ½æŸ¥è¯¢æœåŠ¡")
        
        with patch('app.services.kuaidi100_client.Kuaidi100Client.query_tracking') as mock_query:
            # Mockå¿«é€’100 APIå“åº”
            mock_query.return_value = {
                'success': True,
                'company_code': 'SF',
                'company_name': 'é¡ºä¸°é€Ÿè¿',
                'state': '1',
                'status': 'è¿è¾“ä¸­',
                'data': [
                    {
                        'time': '2024-01-15 10:00:00',
                        'location': 'æ·±åœ³å¸‚',
                        'context': 'å¿«ä»¶å·²å‘å‡º'
                    }
                ]
            }
            
            # åˆ›å»ºæ™ºèƒ½æŸ¥è¯¢æœåŠ¡
            query_service = IntelligentQueryService(self.mock_db)
            
            # æ¨¡æ‹ŸæŸ¥æ‰¾ç†è´§å•çš„æ–¹æ³•
            async def mock_find_manifest(tracking_number):
                if tracking_number == 'E2ETEST001':
                    return manifest
                return None
            
            query_service._find_manifest_by_tracking_number = mock_find_manifest
            
            # æ‰§è¡ŒæŸ¥è¯¢
            result = asyncio.run(query_service.query_tracking('E2ETEST001'))
            
            # è°ƒè¯•è¾“å‡º
            print(f"    æŸ¥è¯¢ç»“æœ: {result}")
            
            # éªŒè¯æŸ¥è¯¢ç»“æœ
            assert result['success'] is True
            assert result['original_tracking_number'] == 'E2ETEST001'
            assert result['query_tracking_number'] == 'PKGE2E001'  # ä½¿ç”¨é›†åŒ…å•å·æŸ¥è¯¢
            assert result['query_type'] == 'package'
            assert result['has_package_association'] is True
            
            # éªŒè¯ç†è´§å•ä¿¡æ¯
            assert result['manifest_info'] is not None
            assert result['manifest_info']['transport_code'] == 'TC001'
            assert result['manifest_info']['customer_code'] == 'CC001'
            
            # éªŒè¯å¿«é€’ä¿¡æ¯
            assert result['tracking_info'] is not None
            assert result['tracking_info']['company_name'] == 'é¡ºä¸°é€Ÿè¿'
            
            # éªŒè¯APIè°ƒç”¨ä½¿ç”¨äº†é›†åŒ…å•å·
            mock_query.assert_called_once()
            call_args = mock_query.call_args[1]
            assert call_args['tracking_number'] == 'PKGE2E001'
        
        print("    âœ“ æ™ºèƒ½æŸ¥è¯¢æœåŠ¡æµ‹è¯•é€šè¿‡")
        print("âœ… æœ‰é›†åŒ…å•å·å…³è”çš„æŸ¥è¯¢æµç¨‹æµ‹è¯•é€šè¿‡")
    
    def test_complete_query_flow_without_package_association(self):
        """
        æµ‹è¯•å®Œæ•´çš„æŸ¥è¯¢æµç¨‹ - æ— é›†åŒ…å•å·å…³è”
        
        æµ‹è¯•åœºæ™¯ï¼š
        1. æŸ¥è¯¢æ— é›†åŒ…å•å·çš„å¿«é€’
        2. éªŒè¯æ™ºèƒ½åˆ¤æ–­é€»è¾‘
        3. éªŒè¯APIè°ƒç”¨å‚æ•°
        """
        print("ğŸ” æµ‹è¯•å®Œæ•´çš„æŸ¥è¯¢æµç¨‹ - æ— é›†åŒ…å•å·å…³è”")
        
        with patch('app.services.kuaidi100_client.Kuaidi100Client.query_tracking') as mock_query:
            mock_query.return_value = {
                'success': True,
                'company_code': 'YTO',
                'company_name': 'åœ†é€šé€Ÿé€’',
                'state': '2',
                'status': 'æ´¾é€ä¸­',
                'data': [
                    {
                        'time': '2024-01-15 14:00:00',
                        'location': 'åŒ—äº¬å¸‚',
                        'context': 'æ­£åœ¨æ´¾é€'
                    }
                ]
            }
            
            # åˆ›å»ºæ™ºèƒ½æŸ¥è¯¢æœåŠ¡
            query_service = IntelligentQueryService(self.mock_db)
            
            # æ¨¡æ‹ŸæŸ¥æ‰¾ç†è´§å•çš„æ–¹æ³•ï¼ˆè¿”å›Noneè¡¨ç¤ºæ— å…³è”ï¼‰
            async def mock_find_manifest(tracking_number):
                return None
            
            query_service._find_manifest_by_tracking_number = mock_find_manifest
            
            # æ‰§è¡ŒæŸ¥è¯¢
            result = asyncio.run(query_service.query_tracking('E2ETEST002'))
            
            # éªŒè¯æŸ¥è¯¢ç»“æœ
            assert result['success'] is True
            assert result['original_tracking_number'] == 'E2ETEST002'
            assert result['query_tracking_number'] == 'E2ETEST002'  # ä½¿ç”¨åŸå•å·æŸ¥è¯¢
            assert result['query_type'] == 'original'
            assert result['has_package_association'] is False
            
            # éªŒè¯APIè°ƒç”¨ä½¿ç”¨äº†åŸå•å·
            mock_query.assert_called_once()
            call_args = mock_query.call_args[1]
            assert call_args['tracking_number'] == 'E2ETEST002'
        
        print("    âœ“ æ™ºèƒ½æŸ¥è¯¢æœåŠ¡æµ‹è¯•é€šè¿‡")
        print("âœ… æ— é›†åŒ…å•å·å…³è”çš„æŸ¥è¯¢æµç¨‹æµ‹è¯•é€šè¿‡")
    
    def test_file_processing_and_data_management(self):
        """
        æµ‹è¯•æ–‡ä»¶å¤„ç†å’Œæ•°æ®ç®¡ç†
        
        æµ‹è¯•åœºæ™¯ï¼š
        1. CSVæ–‡ä»¶è§£æ
        2. æ•°æ®éªŒè¯
        3. å¢é‡æ›´æ–°æœºåˆ¶
        4. ç†è´§å•ç®¡ç†æ“ä½œ
        """
        print("ğŸ” æµ‹è¯•æ–‡ä»¶å¤„ç†å’Œæ•°æ®ç®¡ç†")
        
        # Step 1: æµ‹è¯•CSVæ–‡ä»¶è§£æ
        print("  ğŸ“‹ Step 1: æµ‹è¯•CSVæ–‡ä»¶è§£æ")
        
        test_data = [
            {
                'å¿«é€’å•å·': 'E2EFILE001',
                'ç†è´§æ—¥æœŸ': '2024-01-16',
                'è¿è¾“ä»£ç ': 'TCFILE',
                'å®¢æˆ·ä»£ç ': 'CCFILE',
                'è´§ç‰©ä»£ç ': 'GCFILE',
                'é›†åŒ…å•å·': 'PKGFILE001',
                'é‡é‡': '3.0',
                'é•¿åº¦': '40.0',
                'å®½åº¦': '30.0',
                'é«˜åº¦': '20.0',
                'ç‰¹æ®Šè´¹ç”¨': '25.00'
            }
        ]
        
        csv_content = self.create_test_csv_content(test_data)
        
        # åˆ›å»ºæ–‡ä»¶å¤„ç†æœåŠ¡
        file_processor = FileProcessorService(self.mock_db)
        
        # è§£æCSVæ–‡ä»¶
        df, parse_errors = file_processor.parse_file(csv_content, 'test.csv')
        
        assert parse_errors == []
        assert len(df) == 1
        assert df.iloc[0]['å¿«é€’å•å·'] == 'E2EFILE001'
        
        print("    âœ“ CSVæ–‡ä»¶è§£ææˆåŠŸ")
        
        # Step 2: æµ‹è¯•æ•°æ®éªŒè¯
        print("  âœ… Step 2: æµ‹è¯•æ•°æ®éªŒè¯")
        
        # éªŒè¯åˆ—ç»“æ„
        column_errors = file_processor.validate_columns(df)
        print(f"    åˆ—éªŒè¯é”™è¯¯: {column_errors}")
        assert column_errors == []
        
        # éªŒè¯æ•°æ®å†…å®¹
        validation_result = file_processor.validate_and_preview(csv_content, 'test.csv')
        print(f"    æ•°æ®éªŒè¯ç»“æœ: {validation_result['success']}, é”™è¯¯: {validation_result['errors']}")
        assert validation_result['success'] is True
        assert validation_result['valid_rows'] == 1
        
        # è·å–å¤„ç†åçš„æ•°æ®
        processed_data = []
        for row in validation_result['preview_data']:
            if row['valid']:
                # è½¬æ¢ä¸­æ–‡å­—æ®µåä¸ºè‹±æ–‡å­—æ®µå
                english_data = {}
                chinese_data = row['data']
                field_mapping = {
                    'å¿«é€’å•å·': 'tracking_number',
                    'ç†è´§æ—¥æœŸ': 'manifest_date',
                    'è¿è¾“ä»£ç ': 'transport_code',
                    'å®¢æˆ·ä»£ç ': 'customer_code',
                    'è´§ç‰©ä»£ç ': 'goods_code',
                    'é›†åŒ…å•å·': 'package_number',
                    'é‡é‡': 'weight',
                    'é•¿åº¦': 'length',
                    'å®½åº¦': 'width',
                    'é«˜åº¦': 'height',
                    'ç‰¹æ®Šè´¹ç”¨': 'special_fee'
                }
                for chinese_field, english_field in field_mapping.items():
                    if chinese_field in chinese_data:
                        english_data[english_field] = chinese_data[chinese_field]
                processed_data.append(english_data)
        
        assert len(processed_data) == 1
        assert processed_data[0]['tracking_number'] == 'E2EFILE001'
        
        print("    âœ“ æ•°æ®éªŒè¯é€šè¿‡")
        
        # Step 3: æµ‹è¯•ç†è´§å•ç®¡ç†æœåŠ¡
        print("  ğŸ“Š Step 3: æµ‹è¯•ç†è´§å•ç®¡ç†æœåŠ¡")
        
        # åˆ›å»ºç†è´§å•ç®¡ç†æœåŠ¡
        manifest_service = ManifestService(self.mock_db)
        
        # åˆ›å»ºç†è´§å•
        print(f"    åˆ›å»ºç†è´§å•æ•°æ®: {processed_data[0]}")
        create_result = manifest_service.create_manifest(processed_data[0])
        print(f"    åˆ›å»ºç»“æœ: {create_result}")
        assert create_result['success'] is True
        assert create_result['data']['tracking_number'] == 'E2EFILE001'
        
        print("    âœ“ ç†è´§å•åˆ›å»ºæˆåŠŸ")
        
        # æœç´¢ç†è´§å•
        search_result = manifest_service.search_manifests(search_query='E2EFILE')
        assert search_result['success'] is True
        assert len(search_result['data']) >= 1
        
        print("    âœ“ ç†è´§å•æœç´¢æˆåŠŸ")
        
        print("âœ… æ–‡ä»¶å¤„ç†å’Œæ•°æ®ç®¡ç†æµ‹è¯•é€šè¿‡")
    
    def test_error_handling_scenarios(self):
        """
        æµ‹è¯•é”™è¯¯å¤„ç†åœºæ™¯
        
        æµ‹è¯•åœºæ™¯ï¼š
        1. APIè°ƒç”¨å¤±è´¥å¤„ç†
        2. è¾“å…¥éªŒè¯é”™è¯¯å¤„ç†
        3. æ•°æ®å¤„ç†å¼‚å¸¸å¤„ç†
        """
        print("ğŸ” æµ‹è¯•é”™è¯¯å¤„ç†åœºæ™¯")
        
        # Step 1: æµ‹è¯•APIè°ƒç”¨å¤±è´¥å¤„ç†
        print("  ğŸŒ Step 1: æµ‹è¯•APIè°ƒç”¨å¤±è´¥å¤„ç†")
        
        with patch('app.services.kuaidi100_client.Kuaidi100Client.query_tracking') as mock_query:
            # æ¨¡æ‹Ÿç½‘ç»œé”™è¯¯
            mock_query.side_effect = Exception("Network connection failed")
            
            # åˆ›å»ºæ™ºèƒ½æŸ¥è¯¢æœåŠ¡
            query_service = IntelligentQueryService(self.mock_db)
            
            # æ¨¡æ‹ŸæŸ¥æ‰¾ç†è´§å•çš„æ–¹æ³•
            async def mock_find_manifest(tracking_number):
                return None
            
            query_service._find_manifest_by_tracking_number = mock_find_manifest
            
            # æ‰§è¡ŒæŸ¥è¯¢
            result = asyncio.run(query_service.query_tracking('TESTERROR001'))
            
            # éªŒè¯é”™è¯¯å¤„ç†
            print(f"    é”™è¯¯å¤„ç†ç»“æœ: {result}")
            assert result['success'] is False
            assert 'ç³»ç»Ÿå¼‚å¸¸' in result['error']  # æ™ºèƒ½æŸ¥è¯¢æœåŠ¡è¿”å›é€šç”¨é”™è¯¯æ¶ˆæ¯
        
        print("    âœ“ APIè°ƒç”¨å¤±è´¥å¤„ç†æ­£å¸¸")
        
        # Step 2: æµ‹è¯•è¾“å…¥éªŒè¯é”™è¯¯å¤„ç†
        print("  âœ… Step 2: æµ‹è¯•è¾“å…¥éªŒè¯é”™è¯¯å¤„ç†")
        
        # åˆ›å»ºæ™ºèƒ½æŸ¥è¯¢æœåŠ¡
        query_service = IntelligentQueryService(self.mock_db)
        
        # æµ‹è¯•æ— æ•ˆè¾“å…¥
        result = asyncio.run(query_service.query_tracking('<script>alert("xss")</script>'))
        assert result['success'] is False
        assert 'è¾“å…¥éªŒè¯å¤±è´¥' in result['error']
        
        # æµ‹è¯•ç©ºè¾“å…¥
        result = asyncio.run(query_service.query_tracking(''))
        assert result['success'] is False
        
        print("    âœ“ è¾“å…¥éªŒè¯é”™è¯¯å¤„ç†æ­£å¸¸")
        
        # Step 3: æµ‹è¯•æ–‡ä»¶å¤„ç†é”™è¯¯
        print("  ğŸ“‹ Step 3: æµ‹è¯•æ–‡ä»¶å¤„ç†é”™è¯¯")
        
        # åˆ›å»ºæ–‡ä»¶å¤„ç†æœåŠ¡
        file_processor = FileProcessorService(self.mock_db)
        
        # æµ‹è¯•æ— æ•ˆæ–‡ä»¶å†…å®¹
        invalid_content = b"invalid,csv,content\nwithout,proper,headers"
        df, parse_errors = file_processor.parse_file(invalid_content, 'invalid.csv')
        
        # åº”è¯¥æœ‰è§£æé”™è¯¯æˆ–åˆ—éªŒè¯é”™è¯¯
        if parse_errors == []:
            column_errors = file_processor.validate_columns(df)
            assert len(column_errors) > 0
        else:
            assert len(parse_errors) > 0
        
        print("    âœ“ æ–‡ä»¶å¤„ç†é”™è¯¯å¤„ç†æ­£å¸¸")
        
        print("âœ… é”™è¯¯å¤„ç†åœºæ™¯æµ‹è¯•é€šè¿‡")
    
    def test_data_sync_and_consistency(self):
        """
        æµ‹è¯•æ•°æ®åŒæ­¥å’Œä¸€è‡´æ€§
        
        æµ‹è¯•åœºæ™¯ï¼š
        1. æ•°æ®åŒæ­¥æœåŠ¡åŠŸèƒ½
        2. ç¼“å­˜ä¸€è‡´æ€§
        3. åŒæ­¥ç»Ÿè®¡ä¿¡æ¯
        """
        print("ğŸ” æµ‹è¯•æ•°æ®åŒæ­¥å’Œä¸€è‡´æ€§")
        
        # Step 1: æµ‹è¯•æ•°æ®åŒæ­¥æœåŠ¡åŠŸèƒ½
        print("  ğŸ”„ Step 1: æµ‹è¯•æ•°æ®åŒæ­¥æœåŠ¡åŠŸèƒ½")
        
        # è·å–åŒæ­¥ç»Ÿè®¡ä¿¡æ¯
        stats_before = data_sync_service.get_sync_statistics()
        assert 'cache_size' in stats_before
        assert 'sync_operations' in stats_before
        
        # æ‰‹åŠ¨æ·»åŠ ç¼“å­˜æ•°æ®
        test_data = {
            'tracking_number': 'E2ESYNC001',
            'package_number': 'PKGSYNC001',
            'transport_code': 'TCSYNC'
        }
        
        data_sync_service.cache_manifest('E2ESYNC001', test_data)
        
        # éªŒè¯ç¼“å­˜æ•°æ®
        cached_data = data_sync_service.get_cached_manifest('E2ESYNC001')
        assert cached_data is not None
        assert cached_data['tracking_number'] == 'E2ESYNC001'
        assert cached_data['package_number'] == 'PKGSYNC001'
        
        print("    âœ“ æ•°æ®åŒæ­¥æœåŠ¡åŠŸèƒ½æ­£å¸¸")
        
        # Step 2: æµ‹è¯•ç¼“å­˜å¤±æ•ˆæœºåˆ¶
        print("  ğŸ’¾ Step 2: æµ‹è¯•ç¼“å­˜å¤±æ•ˆæœºåˆ¶")
        
        # å¤±æ•ˆæ‰€æœ‰ç¼“å­˜
        data_sync_service.invalidate_all_cache()
        
        # éªŒè¯ç¼“å­˜è¢«æ¸…ç©º
        cached_data_after = data_sync_service.get_cached_manifest('E2ESYNC001')
        assert cached_data_after is None
        
        # éªŒè¯ç»Ÿè®¡ä¿¡æ¯æ›´æ–°
        stats_after = data_sync_service.get_sync_statistics()
        assert stats_after['cache_size'] == 0
        
        print("    âœ“ ç¼“å­˜å¤±æ•ˆæœºåˆ¶æ­£å¸¸")
        
        print("âœ… æ•°æ®åŒæ­¥å’Œä¸€è‡´æ€§æµ‹è¯•é€šè¿‡")
    
    def test_batch_operations(self):
        """
        æµ‹è¯•æ‰¹é‡æ“ä½œ
        
        æµ‹è¯•åœºæ™¯ï¼š
        1. æ‰¹é‡æ•°æ®å¤„ç†
        2. æ‰¹é‡æŸ¥è¯¢åŠŸèƒ½
        """
        print("ğŸ” æµ‹è¯•æ‰¹é‡æ“ä½œ")
        
        # Step 1: æµ‹è¯•æ‰¹é‡æ•°æ®å¤„ç†
        print("  ğŸ“Š Step 1: æµ‹è¯•æ‰¹é‡æ•°æ®å¤„ç†")
        
        # åˆ›å»ºæ‰¹é‡æµ‹è¯•æ•°æ®
        batch_data = []
        for i in range(5):
            batch_data.append({
                'å¿«é€’å•å·': f'E2EBATCH{i:03d}',
                'ç†è´§æ—¥æœŸ': '2024-01-20',
                'è¿è¾“ä»£ç ': f'TCBATCH{i}',
                'å®¢æˆ·ä»£ç ': f'CCBATCH{i}',
                'è´§ç‰©ä»£ç ': f'GCBATCH{i}',
                'é›†åŒ…å•å·': f'PKGBATCH{i:03d}',
                'é‡é‡': f'{i + 1}.0',
                'é•¿åº¦': '10.0',
                'å®½åº¦': '10.0',
                'é«˜åº¦': '10.0',
                'ç‰¹æ®Šè´¹ç”¨': '5.00'
            })
        
        csv_content = self.create_test_csv_content(batch_data)
        
        # åˆ›å»ºæ–‡ä»¶å¤„ç†æœåŠ¡
        file_processor = FileProcessorService(self.mock_db)
        
        # è§£ææ‰¹é‡æ•°æ®
        df, parse_errors = file_processor.parse_file(csv_content, 'batch.csv')
        assert parse_errors == []
        assert len(df) == 5
        
        # éªŒè¯æ‰¹é‡æ•°æ®
        validation_result = file_processor.validate_and_preview(csv_content, 'batch.csv')
        assert validation_result['success'] is True
        assert validation_result['valid_rows'] == 5
        
        print("    âœ“ æ‰¹é‡æ•°æ®å¤„ç†æˆåŠŸ")
        
        # Step 2: æµ‹è¯•æ‰¹é‡æŸ¥è¯¢åŠŸèƒ½
        print("  ğŸ” Step 2: æµ‹è¯•æ‰¹é‡æŸ¥è¯¢åŠŸèƒ½")
        
        # åˆ›å»ºæ™ºèƒ½æŸ¥è¯¢æœåŠ¡
        query_service = IntelligentQueryService(self.mock_db)
        
        # æ¨¡æ‹Ÿæ‰¹é‡æŸ¥è¯¢
        batch_tracking_numbers = [f'E2EBATCH{i:03d}' for i in range(3)]
        
        with patch('app.services.kuaidi100_client.Kuaidi100Client.query_tracking') as mock_query:
            mock_query.return_value = {
                'success': True,
                'company_code': 'SF',
                'company_name': 'é¡ºä¸°é€Ÿè¿',
                'state': '1',
                'status': 'è¿è¾“ä¸­',
                'data': []
            }
            
            # æ¨¡æ‹ŸæŸ¥æ‰¾ç†è´§å•çš„æ–¹æ³•
            async def mock_find_manifest(tracking_number):
                return None  # ç®€åŒ–å¤„ç†ï¼Œè¿”å›Noneè¡¨ç¤ºæ— å…³è”
            
            query_service._find_manifest_by_tracking_number = mock_find_manifest
            
            # æ‰§è¡Œæ‰¹é‡æŸ¥è¯¢
            result = asyncio.run(query_service.batch_intelligent_query(batch_tracking_numbers))
            
            # éªŒè¯æ‰¹é‡æŸ¥è¯¢ç»“æœ
            assert result['success_count'] == 3
            assert result['failed_count'] == 0
            assert len(result['results']) == 3
        
        print("    âœ“ æ‰¹é‡æŸ¥è¯¢åŠŸèƒ½æ­£å¸¸")
        
        print("âœ… æ‰¹é‡æ“ä½œæµ‹è¯•é€šè¿‡")


def run_final_end_to_end_tests():
    """è¿è¡Œæœ€ç»ˆç‰ˆç«¯åˆ°ç«¯é›†æˆæµ‹è¯•"""
    print("ğŸš€ å¼€å§‹æœ€ç»ˆç‰ˆç«¯åˆ°ç«¯é›†æˆæµ‹è¯•...")
    print("=" * 60)
    
    test_instance = TestEndToEndIntegrationFinal()
    
    try:
        # è¿è¡Œæ‰€æœ‰æµ‹è¯•
        test_instance.setup_method()
        test_instance.test_complete_query_flow_with_package_association()
        print()
        
        test_instance.setup_method()
        test_instance.test_complete_query_flow_without_package_association()
        print()
        
        test_instance.setup_method()
        test_instance.test_file_processing_and_data_management()
        print()
        
        test_instance.setup_method()
        test_instance.test_error_handling_scenarios()
        print()
        
        test_instance.setup_method()
        test_instance.test_data_sync_and_consistency()
        print()
        
        test_instance.setup_method()
        test_instance.test_batch_operations()
        print()
        
        print("=" * 60)
        print("ğŸ‰ æ‰€æœ‰æœ€ç»ˆç‰ˆç«¯åˆ°ç«¯é›†æˆæµ‹è¯•é€šè¿‡ï¼")
        print()
        print("æµ‹è¯•è¦†ç›–èŒƒå›´:")
        print("âœ… å®Œæ•´çš„æŸ¥è¯¢æµç¨‹ï¼ˆæœ‰/æ— é›†åŒ…å•å·å…³è”ï¼‰")
        print("âœ… æ–‡ä»¶å¤„ç†å’Œæ•°æ®ç®¡ç†")
        print("âœ… é”™è¯¯å¤„ç†åœºæ™¯")
        print("âœ… æ•°æ®åŒæ­¥å’Œä¸€è‡´æ€§")
        print("âœ… æ‰¹é‡æ“ä½œåŠŸèƒ½")
        print()
        print("æµ‹è¯•ç‰¹ç‚¹:")
        print("ğŸ“ ç›´æ¥æµ‹è¯•æœåŠ¡å±‚ï¼Œé¿å…å¤æ‚çš„APIå’Œè®¤è¯é—®é¢˜")
        print("ğŸ”§ ä½¿ç”¨Mockå¯¹è±¡æ¨¡æ‹Ÿæ•°æ®åº“å’Œå¤–éƒ¨ä¾èµ–")
        print("ğŸ¯ ä¸“æ³¨äºæ ¸å¿ƒä¸šåŠ¡é€»è¾‘æµ‹è¯•")
        print("âš¡ å¿«é€Ÿæ‰§è¡Œï¼Œæ— å¤–éƒ¨ä¾èµ–")
        print("ğŸ¯ è¦†ç›–ä¸»è¦ä¸šåŠ¡åœºæ™¯å’Œå¼‚å¸¸å¤„ç†")
        
    except Exception as e:
        print(f"\nâŒ æœ€ç»ˆç‰ˆç«¯åˆ°ç«¯é›†æˆæµ‹è¯•å¤±è´¥: {str(e)}")
        import traceback
        traceback.print_exc()
        raise


if __name__ == "__main__":
    run_final_end_to_end_tests()